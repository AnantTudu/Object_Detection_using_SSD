{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "from torchvision import transforms as T\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "es_oleJWGlRo"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SSD(\n",
       "  (backbone): SSDFeatureExtractorVGG(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (6): ReLU(inplace=True)\n",
       "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): ReLU(inplace=True)\n",
       "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): ReLU(inplace=True)\n",
       "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (13): ReLU(inplace=True)\n",
       "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (15): ReLU(inplace=True)\n",
       "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (18): ReLU(inplace=True)\n",
       "      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (20): ReLU(inplace=True)\n",
       "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (22): ReLU(inplace=True)\n",
       "    )\n",
       "    (extra): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (6): ReLU(inplace=True)\n",
       "        (7): Sequential(\n",
       "          (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "          (1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (4): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (3): ReLU(inplace=True)\n",
       "      )\n",
       "      (3-4): 2 x Sequential(\n",
       "        (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (anchor_generator): DefaultBoxGenerator(aspect_ratios=[[2], [2, 3], [2, 3], [2, 3], [2], [2]], clip=True, scales=[0.07, 0.15, 0.33, 0.51, 0.69, 0.87, 1.05], steps=[8, 16, 32, 64, 100, 300])\n",
       "  (head): SSDHead(\n",
       "    (classification_head): SSDClassificationHead(\n",
       "      (module_list): ModuleList(\n",
       "        (0): Conv2d(512, 364, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): Conv2d(1024, 546, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): Conv2d(512, 546, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): Conv2d(256, 546, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4-5): 2 x Conv2d(256, 364, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (regression_head): SSDRegressionHead(\n",
       "      (module_list): ModuleList(\n",
       "        (0): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): Conv2d(1024, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4-5): 2 x Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.48235, 0.45882, 0.40784], std=[0.00392156862745098, 0.00392156862745098, 0.00392156862745098])\n",
       "      Resize(min_size=(300,), max_size=300, mode='bilinear')\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the pre-trained SSD model\n",
    "model = torchvision.models.detection.ssd300_vgg16(weights='SSD300_VGG16_Weights.COCO_V1')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of layers in the SSD300 VGG16 model: 4\n"
     ]
    }
   ],
   "source": [
    "# Count the number of layers in the model\n",
    "layer_count = sum(1 for _ in model.children())\n",
    "print(f'Total number of layers in the SSD300 VGG16 model: {layer_count}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Vw7he960TTMd"
   },
   "outputs": [],
   "source": [
    "# Load the image using PIL\n",
    "ig = Image.open(r'kb.jpg')\n",
    "\n",
    "# Define the transformation (PIL -> Tensor)\n",
    "transform = T.ToTensor()\n",
    "img = transform(ig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ZmLDdG3PcSM-"
   },
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    pred = model([img])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "e-SU2irpcSGn"
   },
   "outputs": [],
   "source": [
    "# Extract bounding boxes, scores, and labels\n",
    "bboxes, scores, labels = pred[0]['boxes'], pred[0]['scores'], pred[0]['labels']\n",
    "\n",
    "# Load class names (replace this with your actual list of COCO class names)\n",
    "coco_names = [\"person\" , \"bicycle\" , \"car\" , \"motorcycle\" , \"airplane\" , \"bus\" , \"train\" , \"truck\" , \"boat\" , \"traffic light\" , \"fire hydrant\" , \"street sign\" , \"stop sign\" , \"parking meter\" , \"bench\" , \"bird\" , \"cat\" , \"dog\" , \"horse\" , \"sheep\" , \"cow\" , \"elephant\" , \"bear\" , \"zebra\" , \"giraffe\" , \"hat\" , \"backpack\" , \"umbrella\" , \"shoe\" , \"eye glasses\" , \"handbag\" , \"tie\" , \"suitcase\" ,\n",
    "\"frisbee\" , \"skis\" , \"snowboard\" , \"sports ball\" , \"kite\" , \"baseball bat\" ,\n",
    "\"baseball glove\" , \"skateboard\" , \"surfboard\" , \"tennis racket\" , \"bottle\" ,\n",
    "\"plate\" , \"wine glass\" , \"cup\" , \"fork\" , \"knife\" , \"spoon\" , \"bowl\" ,\n",
    "\"banana\" , \"apple\" , \"sandwich\" , \"orange\" , \"broccoli\" , \"carrot\" , \"hot dog\" ,\n",
    "\"pizza\" , \"donut\" , \"cake\" , \"chair\" , \"couch\" , \"potted plant\" , \"bed\" ,\n",
    "\"mirror\" , \"dining table\" , \"window\" , \"desk\" , \"toilet\" , \"door\" , \"tv\" ,\n",
    "\"laptop\" , \"mouse\" , \"remote\" , \"keyboard\" , \"cell phone\" , \"microwave\" ,\n",
    "\"oven\" , \"toaster\" , \"sink\" , \"refrigerator\" , \"blender\" , \"book\" ,\n",
    "\"clock\" , \"vase\" , \"scissors\" , \"teddy bear\" , \"hair drier\" , \"toothbrush\" , \"hair brush\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "4mbBq9yvbINH"
   },
   "outputs": [],
   "source": [
    "# Threshold for detection score (you can adjust this)\n",
    "num = torch.argwhere(scores > 0.10).shape[0]\n",
    "\n",
    "# Convert PIL image to OpenCV format\n",
    "igg = cv2.imread(r'kb.jpg')  # Or use: np.array(ig) if you loaded with PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x29LrZZKck8G",
    "outputId": "3c41fca7-55dd-42f6-c1a7-2b285c994bbf"
   },
   "outputs": [],
   "source": [
    "# Draw bounding boxes and labels on the image\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "for i in range(num):\n",
    "    x1, y1, x2, y2 = bboxes[i].numpy().astype('int')\n",
    "    igg = cv2.rectangle(igg, (x1, y1), (x2, y2), (0, 255, 0), 1)\n",
    "    \n",
    "    # Get class name\n",
    "    class_name = coco_names[labels.numpy()[i] - 1]\n",
    "    \n",
    "    # Put label on the image\n",
    "    igg = cv2.putText(igg, class_name, (x1, y1 - 10), font, 0.5, (0, 255, 0), 1, cv2.LINE_AA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "5PT_kSA1nYnf"
   },
   "outputs": [],
   "source": [
    "# Display the image with OpenCV\n",
    "cv2.imshow('Image', igg)\n",
    "cv2.waitKey(0)  # Wait for a key press\n",
    "cv2.destroyAllWindows()  # Close the image window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open video file\n",
    "cap = cv2.VideoCapture('2099536-sd_960_540_30fps.mp4')\n",
    "if not cap.isOpened():\n",
    "    raise IOError('Cannot open video')\n",
    "\n",
    "font_scale = 3\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "\n",
    "# Define transformation for input image\n",
    "transform = T.ToTensor()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert frame (BGR) to PIL image\n",
    "    ig = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    ig = Image.fromarray(ig)\n",
    "\n",
    "    # Apply transformations to the image (PIL -> Tensor)\n",
    "    img = transform(ig)\n",
    "\n",
    "    # Make predictions\n",
    "    with torch.no_grad():\n",
    "        prediction = model([img])\n",
    "\n",
    "    # Extract bounding boxes, scores, and labels\n",
    "    bboxes, scores, labels = prediction[0]['boxes'], prediction[0]['scores'], prediction[0]['labels']\n",
    "\n",
    "    # Threshold for detection score (you can adjust this)\n",
    "    num = torch.argwhere(scores > 0.55).shape[0]\n",
    "\n",
    "    # Draw bounding boxes and labels on the frame\n",
    "    for i in range(num):\n",
    "        x1, y1, x2, y2 = bboxes[i].numpy().astype('int')\n",
    "        label = coco_names[labels[i].item() - 1]\n",
    "        confidence = scores[i].item()\n",
    "\n",
    "        # Draw rectangle and label\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "        # cv2.putText(frame, f\"{label} ({confidence:.2f})\", (x1, y1 - 10), font, fontScale=font_scale, color=(0, 255, 0), thickness=3)\n",
    "        cv2.putText(frame, label, (x1, y1 - 10), font, fontScale=font_scale, color=(0, 255, 0), thickness=3)\n",
    "\n",
    "\n",
    "    # Display the frame with detection\n",
    "    cv2.imshow('Object Detection', frame)\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(2) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
